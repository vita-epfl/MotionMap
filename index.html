<!DOCTYPE html><html><head><link href="https://fonts.googleapis.com/css?family=Arial&display=swap" rel="stylesheet" /><link href="./css/main.css" rel="stylesheet" /><title>Document</title></head><body><div class="v1_400"><div class="name"></div><span class="v1_404">¬† ¬† ¬†üö∂‚Äç‚ôÄÔ∏è¬† ¬† ¬† </span><div class="name"></div><div class="v1_408"></div><span class="v1_409">Human pose forecasting is inherently multimodal since multiple futures exist</span><span class="v1_412">for an observed pose sequence. However, evaluating multimodality is</span><span class="v1_413">challenging since the task is ill-posed. Therefore, we first propose an</span><span class="v1_414">alternative paradigm to make the task well-posed. Next, while state-of-the-art</span><span class="v1_415">methods predict multimodality, this requires oversampling a large volume of</span><span class="v1_416">predictions. This raises key questions:</span><span class="v1_417">(1) Can we capture multimodality by efficiently sampling a smaller number of</span><span class="v1_418">predictions?</span><span class="v1_419">(2) Subsequently, which of the predicted futures is more likely for an observed</span><span class="v1_420">pose sequence?</span><span class="v1_421">We address these questions with MotionMap, a simple yet effective heatmap</span><span class="v1_422">based representation for multimodality. We extend heatmaps to represent a</span><span class="v1_423">spatial distribution over the space of all possible motions, where different</span><span class="v1_424">local maxima correspond to different forecasts for a given observation.</span><span class="v1_425">MotionMap can capture a variable number of modes per observation and</span><span class="v1_426">provide confidence measures for different modes. Further, MotionMap allows</span><span class="v1_427">us to introduce the</span><span class="v1_428">notion of uncertainty and controllability over the forecasted pose sequence.</span><span class="v1_429">Finally, MotionMap captures rare modes that are non-trivial to evaluate yet</span><span class="v1_430">critical for safety. We support our claims through multiple qualitative and</span><span class="v1_431">quantitative experiments using popular 3D human pose datasets:</span><span class="v1_432">Human3.6M and AMASS, highlighting the strengths and limitations of our</span><span class="v1_433">proposed method.</span><span class="v1_434">Architecture</span><div class="v1_438"><div class="v1_440"></div><div class="v1_442"><span class="v1_443">We define a two-stage training pipeline for human pose forecasting. At first, we train a framework
similar to an autoencoder to predict the ground truth and future motion. At test time since we do not
have the future motion as input, we train a heatmap model to predict MotionMap, which encodes the
likely motions and their latents as a drop-in replacement. At inference time, we use the predicted
MotionMap to obtain latents corresponding to motions with a high likelihood and use it in tandem
with the observed pose sequence to predict the future pose sequence.</span></div></div><span class="v1_446">Results</span><span class="v1_448">controllability</span><div class="v1_450"><div class="v1_451"><div class="v1_452"><div class="v1_453"></div><div class="name"></div></div><div class="v1_454"><span class="v1_456">MotionMap example 1:
Red crosses mark the modes selected by the model. We can view the decoded future
poses corresponding to the given input pose sequence by selection.</span><span class="v1_458">1/5</span></div></div><div class="v1_460"><div class="v1_461"><div class="v1_462"></div></div><div class="v1_463"><div class="v1_464"></div></div></div><div class="v1_465"><div class="v1_466"><div class="v1_467"></div></div><div class="v1_468"><div class="v1_469"></div></div></div><div class="v1_470"><div class="v1_471"><div class="v1_472"></div></div><div class="v1_473"><div class="v1_474"></div></div></div><div class="v1_475"><div class="v1_476"><div class="v1_477"></div></div><div class="v1_478"><div class="v1_479"></div></div></div></div><div class="name"></div><div class="name"></div><div class="v1_489"><div class="v1_490"><div class="v1_493"></div><div class="v1_495"><span class="v1_496">MotionMap exam
Red crosses mar</span></div><div class="v1_497"></div></div><div class="v1_499"><div class="v1_500"></div><div class="v1_501"><span class="v1_502">MotionMap exam
Red crosses mar</span></div></div><div class="v1_503"><div class="v1_504"></div><div class="v1_505"><span class="v1_506">MotionMap exam
Along with the re
the selection of a </span></div></div><div class="v1_507"><div class="v1_508"></div><div class="v1_509"><span class="v1_510">MotionMap exam
Red crosses mar</span></div></div><div class="v1_511"><div class="v1_512"></div><div class="v1_513"><span class="v1_514">MotionMap exam
Red crosses mar</span></div></div></div><span class="v1_516">Uncertainty</span><div class="v1_518"><span class="v1_521">Forecasted future poses and their corresponding predicted uncertainty per joint and time frame.</span><div class="v1_520"></div></div><span class="v1_522">Quantitative</span><div class="v1_524"></div></div></body></html>